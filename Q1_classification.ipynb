{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q1_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMaeiX9U--Hr"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3jKcvO6Zl8a"
      },
      "source": [
        "# This function loads the file into a dataframe using pandas.\n",
        "def load_file(fileName):\n",
        "    dataset = pd.read_table(fileName, header=0, sep=\",\", encoding=\"unicode_escape\")\n",
        "    return dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDNoGmj4Znh8"
      },
      "source": [
        "# preprocess creates the term frequency matrix for the review data set\n",
        "def preprocess(data):\n",
        "    count_vectorizer = CountVectorizer()\n",
        "    data = count_vectorizer.fit_transform(data)\n",
        "    #tfidf_data = TfidfTransformer(use_idf=False).fit_transform(data)\n",
        "    return data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3sGNIKsZrBP"
      },
      "source": [
        "# This function learns the model by finding class probabilities and conditional probabilities of each word\n",
        "# given a particular class. The classifier with both these attributes as well as the classes list is returned. \n",
        "def learn_model(data,target):\n",
        "  \n",
        "    classifier = dict() # Classifier to be returned\n",
        "\n",
        "    # Create two arrays - one for storing classes and other for storing corresponding frequencies of each class in data\n",
        "    classes, class_frequency = np.unique(target, return_counts = True)\n",
        "\n",
        "    # Convert data to array\n",
        "    corpus = data.toarray()\n",
        "\n",
        "    # Initialize structures to store class probabilities and conditional probabilities for Naive Bayes classifier\n",
        "    class_probs = dict()\n",
        "    conditional_probs = np.zeros((len(classes), corpus.shape[1]), dtype = float)\n",
        "\n",
        "    # Loop runs for each class\n",
        "    for i in range(len(classes)):\n",
        "\n",
        "      # Finding probability of each class in the given dataset using frequencies\n",
        "      class_probs[classes[i]] = (class_frequency[i] / np.sum(class_frequency))\n",
        "      \n",
        "      # Finding all docs in the data for the particular class in this iteration of loop\n",
        "      docs_in_class = np.where(target == classes[i])\n",
        "      corpus_for_class = (np.take(corpus, axis = 0, indices=docs_in_class))[0]\n",
        "\n",
        "      # Finding conditional probabilites for each word given this particular class after Laplace Smoothing\n",
        "      conditional_probs[i] = (np.sum(corpus_for_class, axis = 0) + 1) # the + 1 incorporates for Laplace smoothing\n",
        "      conditional_probs[i] /= np.sum(conditional_probs[i])\n",
        " \n",
        "    # The classifier is set up before returning  \n",
        "    classifier[\"Conditional Probabilites\"] = conditional_probs\n",
        "    classifier[\"Class Probabilites\"] = class_probs\n",
        "    classifier[\"Classes\"] = classes\n",
        " \n",
        "    return classifier\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTaEIvMqZtaq"
      },
      "source": [
        "# This function takes in the classifier and uses that to predict the class of the testdata\n",
        "def classify(classifier, testdata):\n",
        "    \n",
        "    # The array to return from this functions\n",
        "    predicted_val=[]\n",
        "\n",
        "    # Convert testdata to array\n",
        "    corpus = testdata.toarray()\n",
        "\n",
        "    # Dereferencing data from the classifier\n",
        "    conditional_probabilities = classifier[\"Conditional Probabilites\"]\n",
        "    class_probs = classifier[\"Class Probabilites\"]\n",
        "    classes = classifier[\"Classes\"]\n",
        "\n",
        "    # This loop runs for each doc in testdata\n",
        "    for i in range(corpus.shape[0]):\n",
        "\n",
        "      # Finding words that exist in this particular doc\n",
        "      words_in_doc = np.where(corpus[i] > 0)\n",
        "\n",
        "      # Initializing array of predicted probabilities for each class this doc could belong to\n",
        "      predicted_probs = np.zeros(6, dtype = float)\n",
        "\n",
        "      # This loop runs for each possible class the doc could belong to\n",
        "      for j in range(len(classes)):\n",
        "\n",
        "        # We choose the conditional probabilities given this particular class for the words in this particular doc\n",
        "        chosen_probs = (np.take(conditional_probabilities[j], indices=words_in_doc))[0]\n",
        "\n",
        "        # We multiply all the conditional probabilities and the probability of this particular class\n",
        "        predicted_probs[j] = np.prod(chosen_probs) * class_probs[classes[j]]\n",
        "      \n",
        "      # Finding the maximum likelihood of the class that this particular doc belongs to, choosing the max one to append \n",
        "      max_index = np.where(predicted_probs == np.amax(predicted_probs))\n",
        "      predicted_val.append(classes[max_index][0])\n",
        "\n",
        "    return predicted_val"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlZYlEA7ZwKU"
      },
      "source": [
        "# This function evaluates the metrics of our learned model\n",
        "def evaluate(actual_class, predicted_class):\n",
        "    \n",
        "    # Generate the confusion matrix and get its dimension\n",
        "    conf_mat = confusion_matrix(actual_class, predicted_class)\n",
        "    dim = conf_mat.shape[0]\n",
        "\n",
        "    # Initializing True-Positive, True-Negative, False-Positive, False-Negative. \n",
        "    # These metrics will be found in arrays corresponding to each class label. \n",
        "    TP = []\n",
        "    TN = []\n",
        "    FP = []\n",
        "    FN = []\n",
        "\n",
        "    # Calculating TP from confusion matrix -> TP of each class = its respective diagonal \n",
        "    for i in range(dim):\n",
        "      for j in range(dim):\n",
        "        if(i == j):\n",
        "          TP.append(conf_mat[i][j])\n",
        "\n",
        "    # Calculating the accuracy of the model as a whole\n",
        "    accuracy = np.sum(TP) / len(actual_class)\n",
        "    \n",
        "\n",
        "    # Calculating TN from confusion matrix. This is different for each class label as negative would mean predicting\n",
        "    # any class, other than the one in question, correctly. \n",
        "    for i in range(dim):\n",
        "      total = 0\n",
        "      for j in range(dim):\n",
        "        for k in range(dim):\n",
        "          if(j != i and k != i):\n",
        "            total += conf_mat[j][k]\n",
        "      TN.append(total)\n",
        "\n",
        "    \n",
        "    # Calculating FP from confusion matrix. This is different for each class label due to similar reasons as TN.\n",
        "    for i in range(dim):\n",
        "      total = 0\n",
        "      for j in range(dim):\n",
        "        if(j != i):\n",
        "          total += conf_mat[i][j]\n",
        "\n",
        "      FP.append(total)\n",
        "        \n",
        "    # Calculating FN from confusion matrix. This is different for each class label due to similar reasons as TN.    \n",
        "    for j in range(dim):\n",
        "      total = 0\n",
        "      for i in range(dim):\n",
        "        if(j != i):\n",
        "          total += conf_mat[i][j]\n",
        "\n",
        "      FN.append(total)\n",
        "\n",
        "\n",
        "    # Initializing arrays. These metrics would be different for each class label due to difference in TN, FP, FN.\n",
        "\n",
        "    precision = [] # TP / (TP + FP)\n",
        "    recall = [] # TP / (TP + FN)\n",
        "    f_measure = [] # 2TP / (2TP + FP + FN)\n",
        "\n",
        "    \n",
        "    for i in range(dim):\n",
        "      if(TP[i] != 0):\n",
        "        precision.append(TP[i] / (TP[i] + FP[i]))\n",
        "        recall.append(TP[i] / (TP[i] + FN[i]))\n",
        "        f_measure.append((2* TP[i]) / ((2 * TP[i]) + FP[i] + FN[i]))\n",
        "\n",
        "      else:\n",
        "        precision.append(0)\n",
        "        recall.append(0)\n",
        "        f_measure.append(0)\n",
        "    \n",
        "    print(\"The accuracy score for the overall model is :\",accuracy)\n",
        "    print(f\"The accuracy percentage for the overall model is: {accuracy*100} %\")\n",
        "    print(\"The precision score for each label is :\",precision)\n",
        "    print(\"The recall score for each label is :\",recall)\n",
        "    print(\"The F measure score for each label is :\",f_measure)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuiUyNGGZyVK",
        "outputId": "5d6732fd-8d05-43ad-d348-37f5a4acdaf3"
      },
      "source": [
        "features = [\"SUMMARY\", \"categories\", \"sub_categories\"]\n",
        "\n",
        "print(\"Loading data.....\")\n",
        "dataset = load_file(\"TextClassification_Data.csv\")\n",
        "\n",
        "dataset = dataset.dropna() #added\n",
        "\n",
        "data,target = dataset[features[0]].fillna(\" \"), dataset[features[1]]\n",
        "\n",
        "print(\"preprocessing data.....\")\n",
        "word_vectors = preprocess(data)\n",
        "\n",
        "trainingX,testX,trainingY,testY = train_test_split(word_vectors,target,test_size=0.4,random_state=43)\n",
        "\n",
        "print(\"Learning model.....\")\n",
        "model = learn_model(trainingX,trainingY)\n",
        "\n",
        "print(\"Classifying test data......\")      \n",
        "predictedY = classify(model, testX)\n",
        "\n",
        "print(\"Evaluating results.....\")\n",
        "evaluate(testY,predictedY)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data.....\n",
            "preprocessing data.....\n",
            "Learning model.....\n",
            "Classifying test data......\n",
            "Evaluating results.....\n",
            "The accuracy score for the overall model is : 0.7341707611013256\n",
            "The accuracy percentage for the overall model is: 73.41707611013256 %\n",
            "The precision score for each label is : [0.795196671709531, 0.6357758620689655, 0, 0.6395759717314488, 0.7037481979817396, 0.8080650744202146]\n",
            "The recall score for each label is : [0.8133462282398453, 0.6758304696449027, 0, 0.7288590604026846, 0.6130179991628296, 0.8090452261306532]\n",
            "The F measure score for each label is : [0.8041690571811054, 0.6551915602443087, 0, 0.6813048933500627, 0.6552572706935123, 0.8085548532340462]\n"
          ]
        }
      ]
    }
  ]
}